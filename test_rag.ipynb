{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f32689-42f8-4056-8aa9-22d09b6ec100",
   "metadata": {},
   "source": [
    "### RAG Test Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a084b-1855-4e0f-9283-e4b1a4192e42",
   "metadata": {},
   "source": [
    "#### openai_api_key can also be directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd4bd3-78a9-4059-a071-d60bac4b20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d84b82-6ae3-4763-aa36-a436e6b39951",
   "metadata": {},
   "source": [
    "#### Same for pinecone API key. I used apple-index as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c351a3e-33af-4c62-bd1f-a828080298fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import dspy\n",
    "from dspy.retrieve.pinecone_rm import PineconeRM\n",
    "import openai\n",
    "\n",
    "\n",
    "# Although we didn't use local embedding model, dspy still requires us to install torch. Very weird.\n",
    "try:\n",
    "    __import__('torch')\n",
    "except ImportError:\n",
    "    pip.main(['install', 'torch'])    \n",
    "\n",
    "llm = dspy.OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "pinecone_index_name = \"apple-index\"\n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n",
    "pinecone_env = \"us-east-1-aws\"\n",
    "\n",
    "retriever_model = PineconeRM(pinecone_index_name, \n",
    "                             pinecone_api_key, \n",
    "                             pinecone_env,\n",
    "                             None, \n",
    "                             'text-embedding-ada-002',\n",
    "                             openai_api_key,\n",
    "                             None, \n",
    "                             5)\n",
    "dspy.settings.configure(lm=llm, rm=retriever_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf85051-a62e-423b-9fa1-a4607d7a64ec",
   "metadata": {},
   "source": [
    "#### Testing if dspy connects to LMs (gpt-3.5 and gpt-4 are being used here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc54b92a-129f-4a22-ba1d-87c976c691c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neural networks, a web of connections so vast,\\nLearning and adapting, evolving fast,\\nMimicking the human brain, a future forecast.']\n",
      "['In the realm where data streams flow,\\nNeural networks learn, adapt and grow,\\nA dance of code, a silent show.']\n"
     ]
    }
   ],
   "source": [
    "print(dspy.settings.lm(\"Write a 3 line poem about neural networks.\"))\n",
    "context_example = dspy.OpenAI(model=\"gpt-4\")\n",
    "\n",
    "with dspy.context(llm=context_example):\n",
    "    print(context_example(\"Write a 3 line poem about neural networks.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c1178-dd10-41f0-be57-1e61b692218a",
   "metadata": {},
   "source": [
    "#### Create a metric on a different model. This metric program is a recipe from [Weviate Recipe Github](https://github.com/weaviate/recipes/tree/main/integrations/dspy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bbb9b41-e592-485c-90e5-18092b47a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricLM = dspy.OpenAI(model='gpt-4', max_tokens=1000, model_type='chat')\n",
    "\n",
    "# Signature for LLM assessments.\n",
    "\n",
    "class Assess(dspy.Signature):\n",
    "    \"\"\"Assess the quality of an answer to a question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"The context for answering the question.\")\n",
    "    assessed_question = dspy.InputField(desc=\"The evaluation criterion.\")\n",
    "    assessed_answer = dspy.InputField(desc=\"The answer to the question.\")\n",
    "    assessment_answer = dspy.OutputField(desc=\"A rating between 1 and 5. Only output the rating and nothing else.\")\n",
    "\n",
    "def llm_metric(gold, pred, trace=None):\n",
    "    predicted_answer = pred.answer\n",
    "    question = gold.question\n",
    "    \n",
    "    print(f\"Test Question: {question}\")\n",
    "    print(f\"Predicted Answer: {predicted_answer}\")\n",
    "    \n",
    "    detail = \"Is the assessed answer detailed?\"\n",
    "    faithful = \"Is the assessed text grounded in the context? Say no if it includes significant facts not in the context.\"\n",
    "    overall = f\"Please rate how well this answer answers the question, `{question}` based on the context.\\n `{predicted_answer}`\"\n",
    "    \n",
    "    with dspy.context(lm=metricLM):\n",
    "        retrieve = dspy.Retrieve(k=3)\n",
    "        context = retrieve(question).passages\n",
    "        detail = dspy.ChainOfThought(Assess)(context=\"N/A\", assessed_question=detail, assessed_answer=predicted_answer)\n",
    "        faithful = dspy.ChainOfThought(Assess)(context=context, assessed_question=faithful, assessed_answer=predicted_answer)\n",
    "        overall = dspy.ChainOfThought(Assess)(context=context, assessed_question=overall, assessed_answer=predicted_answer)\n",
    "    \n",
    "    print(f\"Faithful: {faithful.assessment_answer}\")\n",
    "    print(f\"Detail: {detail.assessment_answer}\")\n",
    "    print(f\"Overall: {overall.assessment_answer}\")\n",
    "    \n",
    "    \n",
    "    total = float(detail.assessment_answer) + float(faithful.assessment_answer)*2 + float(overall.assessment_answer)\n",
    "    \n",
    "    return total / 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737db71b-c993-49a1-a289-a3adab67a24a",
   "metadata": {},
   "source": [
    "#### Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95596bcd-f1ce-44e1-afc4-0ec97c0d31df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: What do cross encoders do?\n",
      "Predicted Answer: They re-rank documents.\n",
      "Faithful: 1\n",
      "Detail: 1\n",
      "Overall: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = dspy.Example(question=\"What do cross encoders do?\")\n",
    "test_pred = dspy.Example(answer=\"They re-rank documents.\")\n",
    "\n",
    "type(llm_metric(test_example, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479911a-08db-4641-bc16-ffdc031e7ee0",
   "metadata": {},
   "source": [
    "#### Define a Signature for our RAG. Signature: \"question, context ---> answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03666151-3ecb-4057-b07b-b334800a9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSignature(dspy.Signature):\n",
    "    \"\"\"Answer questions based on context. Answer I don't know if the question cannot be answered given the context.\"\"\"\n",
    "    \n",
    "    question = dspy.InputField()\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    answer = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f13a6-a97c-4291-aa6c-064526420b92",
   "metadata": {},
   "source": [
    "#### Define RAG Program. retrieves passages from our pinecone \"apple-index\" index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb1a5d7b-c6da-4d8a-9f32-972493e6c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(RAGSignature)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        print(context)\n",
    "        prediction = self.generate_answer(question=question, context=context)\n",
    "        return dspy.Prediction(answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecc22f-7c07-4a2a-ba10-0552949acc89",
   "metadata": {},
   "source": [
    "#### Actual RAG Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "167848f0-c292-4f8f-91d6-93483ef1494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Third Quarter 2023:\\n\\n• MacBook Air 15”, Mac Studio and Mac Pro;\\n• Apple Vision Pro™, the Company’s first spatial computer featuring its new visionOS™, expected to be available in early calendar year 2024; and\\n• iOS 17, macOS Sonoma, iPadOS 17, tvOS 17 and watchOS 10, updates to the Company’s operating systems.\\n\\nFourth Quarter 2023:\\n\\n• iPhone 15, iPhone 15 Plus, iPhone 15 Pro and iPhone 15 Pro Max; and\\n• Apple Watch Series 9 and Apple Watch Ultra 2.']\n",
      "Question: What new products did apple release in each of the quarter this year? List the result as bullet points.\n",
      "Predicted Answer: - Third Quarter 2023:\n",
      "  • MacBook Air 15”, Mac Studio and Mac Pro\n",
      "  • Apple Vision Pro™\n",
      "  • iOS 17, macOS Sonoma, iPadOS 17, tvOS 17 and watchOS 10\n",
      "\n",
      "- Fourth Quarter 2023:\n",
      "  • iPhone 15, iPhone 15 Plus, iPhone 15 Pro and iPhone 15 Pro Max\n",
      "  • Apple Watch Series 9 and Apple Watch Ultra 2\n"
     ]
    }
   ],
   "source": [
    "generate_answer = RAG(num_passages=10)\n",
    "\n",
    "question = \"What new products did apple release in each of the quarter this year? List the result as bullet points.\"\n",
    "#retrieve = dspy.Retrieve(k = 3)\n",
    "#topK_passages = retrieve(question).passages\n",
    "\n",
    "pred = generate_answer(question=question)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a7f82-6b41-406e-935e-5e16b247db0b",
   "metadata": {},
   "source": [
    "### Inspect the query sent to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22036c79-0558-470c-84d7-cb9afe635b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions based on context. Answer I don't know if the question cannot be answered given the context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: What new products did apple release in each of the quarter this year? List the result as bullet points.\n",
      "\n",
      "Context:\n",
      "«Third Quarter 2023:\n",
      "\n",
      "• MacBook Air 15”, Mac Studio and Mac Pro;\n",
      "• Apple Vision Pro™, the Company’s first spatial computer featuring its new visionOS™, expected to be available in early calendar year 2024; and\n",
      "• iOS 17, macOS Sonoma, iPadOS 17, tvOS 17 and watchOS 10, updates to the Company’s operating systems.\n",
      "\n",
      "Fourth Quarter 2023:\n",
      "\n",
      "• iPhone 15, iPhone 15 Plus, iPhone 15 Pro and iPhone 15 Pro Max; and\n",
      "• Apple Watch Series 9 and Apple Watch Ultra 2.»\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We need to look at the products released by Apple in the third and fourth quarters of 2023 and list them as bullet points.\n",
      "\n",
      "Answer:\n",
      "- Third Quarter 2023:\n",
      "  • MacBook Air 15”, Mac Studio and Mac Pro\n",
      "  • Apple Vision Pro™\n",
      "  • iOS 17, macOS Sonoma, iPadOS 17, tvOS 17 and watchOS 10\n",
      "\n",
      "- Fourth Quarter 2023:\n",
      "  • iPhone 15, iPhone 15 Plus, iPhone 15 Pro and iPhone 15 Pro Max\n",
      "  • Apple Watch Series 9 and Apple Watch Ultra 2\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm.inspect_history(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d197fa-7609-43aa-b1ab-7b107da63579",
   "metadata": {},
   "source": [
    "## More to be added..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
